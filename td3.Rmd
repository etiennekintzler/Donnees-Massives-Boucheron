---
title: "Compte-rendu du TP4"
author: "Etienne Kintzler"
output: html_document
header-includes:
   - \usepackage{dsfont}

---
Le jeu de donnée "Parkinsons" a été selectionné. L'URL est le suivant : https://archive.ics.uci.edu/ml/machine-learning-databases/parkinsons/

\section{1. Description des données}

\subsection{1.1. Caractéristiques des données}

Le jeu de donnée est constituée d'enregistrement biomédicale de voix de 31 personnes
dont 23 sont atteint de la maladie de Parkinson. En ligne sont représentés 195 enregistrements (soit environ 6 enregistrements pour chaque sujet)
de voix et en colonne différentes caractéristiques des voix mesurées. Sur les 195 enregistrements, 147 correspondent à des individus atteints par la maladie de parkinson et 48 correspondent à des individus saints.
Pour chaque échantillon nous disposons de l'étiquette indiquant si le sujet correspondant est atteint de la maladie de Parkinson (\textit{status}=1) ou non (\textit{status}=0).
L'ensemble des variables explicatives est de type réel et la variable expliquée est de type entière ($\in \{0,1\}$). 

\subsection{1.2. Moment de premier ordre}

Nous nous intéressons ici aux valeurs moyennes pour chacun des groupe: le groupe des individus saints et le groupe des individus malades. Le code ci-dessous calcule la valeur moyenne de chacune des variables en fonction du \textit{status} puis réalise un graphique à barres des ces moyennes.
```{r}
#setwd("./apprentissage stat")
data            <- read.table("parkinsons.data",head=T,sep=",",dec=".",row.names="name")
agg.data        <- aggregate(data[,!(colnames(data) %in% "status" )], list(data$status), mean)
mymat           <- t(agg.data[,-1])
colnames(mymat) <- c("Saint","Malade")
barplot(t(mymat)[,1:nrow(mymat)],beside=T,col=c("darkblue","red"),las=2)
legend("topright",legend = colnames(mymat),fill = c("darkblue", "red"),cex=0.5,horiz=T)
```


Le graphique  ne permettant pas de faire apparaitre l'ensemble des différences entre les \textit{status} du fait des différences d'échelle, nous représentons ci-dessous le rapport des différentes variables entre les individus saints et malades.
```{r}
barplot(mymat[,1]/mymat[,2],cex.names=0.6,las=2)
abline(h=1,lty=5,col="red")
```

Le graphique ci-dessus fait ainsi apparaître des différences très considérables entre les valeurs moyennes des individus saints et celles des individus malades. Une valeur située au-dessus des pointillés rouge signifie que la moyenne pour cette variable est plus élevée chez les individus saints que chez les individus malades. Par exemple, la moyenne pour la variable \textit{MDVP.Fhi.Hz} (2ème colonne) est 20% fois plus élevée chez les individus saints que chez les individus malades.

Ce type de base de donnée se prête particulièrement bien à un travail d'apprentissage supervisé, dans la mesure où nous disposons d'étiquettes (en un nombre suffisant). Nous réaliserons deux types de régression: une régression logistique et une régression par forêt aléatoire.



\section{2. Réalisation des régressions}
\subsection{2.1. Régression logistique}
\subsubsection{2.1.1. Résultats de la régression logistique}
La régression logistique est effectué en R à l'aide de la commande \texttt{glm}.

```{r,warning=F,error=F}
model.logistique <- glm(status ~ . ,data=data,family=binomial(link = "logit"))
```
 
 Le tableau suivant présente les résultats de la régression logistique:
\begin{table}[ht!]
\centering
\caption{Table de régression pour le modèle logistique}
\begin{tabular}{lllll}
\\[-1.8ex]\hline 
\hline \\[-1.8ex] 
 & Estimate & Std. Error & z value & Pr($>$$|$z$|$) \\ 
  \hline
(Intercept) & -12.2358 & 17.3015 & -0.71 & 0.4794 \\ 
  MDVP.Fo.Hz. & -0.0119 & 0.0200 & -0.59 & 0.5538 \\ 
  MDVP.Fhi.Hz. & -0.0024 & 0.0039 & -0.63 & 0.5312 \\ 
  MDVP.Flo.Hz. & 0.0034 & 0.0112 & 0.30 & 0.7635 \\ 
  MDVP.Jitter... & -1412.5603 & 1131.1097 & -1.25 & 0.2117 \\ 
  MDVP.Jitter.Abs. & -42422.1412 & 87700.5328 & -0.48 & 0.6286 \\ 
  MDVP.RAP & 1813.2765 & 123994.8618 & 0.01 & 0.9883 \\ 
  MDVP.PPQ & -1915.8332 & 1829.6686 & -1.05 & 0.2951 \\ 
  Jitter.DDP & 672.8649 & 41355.4468 & 0.02 & 0.9870 \\ 
  MDVP.Shimmer & 347.9939 & 934.0069 & 0.37 & 0.7095 \\ 
  MDVP.Shimmer.dB. & 23.5389 & 30.7161 & 0.77 & 0.4435 \\ 
  Shimmer.APQ3 & 12864.7729 & 108261.2991 & 0.12 & 0.9054 \\ 
  Shimmer.APQ5 & -262.6843 & 415.9165 & -0.63 & 0.5277 \\ 
  MDVP.APQ & 218.1311 & 366.7050 & 0.59 & 0.5519 \\ 
  Shimmer.DDA & -4563.0569 & 36115.0701 & -0.13 & 0.8995 \\ 
  NHR & 20.5868 & 50.8529 & 0.40 & 0.6856 \\ 
  HNR & 0.0521 & 0.2053 & 0.25 & 0.7997 \\ 
  RPDE & -3.2134 & 4.7596 & -0.68 & 0.4996 \\ 
  DFA & 7.5631 & 8.7211 & 0.87 & 0.3858 \\ 
  spread1 & 0.0465 & 1.6735 & 0.03 & 0.9778 \\ 
  spread2 & 10.4735 & 6.0508 & 1.73 & 0.0835 .\\ 
  D2 & 1.2238 & 1.4104 & 0.87 & 0.3856 \\ 
  PPE & 36.5781 & 24.5805 & 1.49 & 0.1367 \\ 
   \hline
\end{tabular}
\end{table}

La quasi-majorité des variables ne sont pas significatives. Toutefois quatre variables
(sans compter la constante) sont significatives à un seuil d'au moins 10\%. Ainsi,
les mesure MDVP:Jitter(\%) et spread2 sont significatives à un seuil d'au moins 1\%.
La variable RPDE est significative à un seuil d'au moins 5\%. Enfin la variable MDVP.Flo.Hz.  
est significative à un seuil d'au moins 10\%.

\subsubsection{2.1.2. Prédiction sur l'ensemble de l'échantillon}
On s'intéresse maintenant aux valeurs prédites par la régression. Dans le cadre d'une classification binaire, la meilleur fonction de prédiction est donnée par $g_p^*(x)\in argmax_{y \in \mathcal{Y}} P(Y=y|X=x)$
et la fonction oracle s'écrit : $\mathds{1}_{P(Y=y|X=x)>1/2}$. Le code R permettant
d'obtenir cette fonction est le suivant:
```{r}
pred.log <- ifelse(model.logistique$fitted.values>0.5,1,0)  
```
Il s'agit ensuite de comparer cette prédiction avec les réalisations. Pour cela on utilise la fonction \texttt{table}: 

```{r,eval=FALSE}
table(pred.log,data[,"status"])
```

Les résultats sont présentés dans la table suivante:

\begin{table}[h!]
\centering
\caption{Matrice de confusion pour la régression logistique, en échantillon }

\begin{tabular}{lcc}
\\[-1ex]
prédiction $\backslash$ réalisation & 0 & 1 \\
\hline
0 & 35 & 7 \\
1 & 13 & 140
\end{tabular}
\end{table}
La diagonale indique les valeur correctement prédites. Globalement le modèle semble bien performer.
Sur les 147 échantillons d'invidus malade, le modèle en reconnaît 140 et se trompe sur 13 échantillons, qu'il indique comme étant des échantillons malades alors que ce n'est pas le cas. Sur les 48 échantillons saints, le modèle prédit correctement la valeur de 35 échantillons et se trompe sur 7 (qu'il indique comme étant des échantillons saints alors que ce n'est pas le cas). Enfin, on remarque que le risque que le modèle prédise un échantillon comme étant saint alors que ce n'est pas le cas (risque d'intérêt en médecine) est assez faible car 7 échantillons malades (sur les 147) ne sont pas detectés (soit un risque d'un peu moins de 5\%).


\subsubsection{2.2.2. Exercice de prédiction hors-échantillon}

Nous testons dans cette sous-section les capacités prédictives hors-échantillon du modèle.
Le modèle apprend alors sur un échantillon d'apprentissage, représentant deux-tiers des observations et prédit sur un échantillon test.

```{r,warning=F}
set.seed(123)
number.train      <- sample(nrow(data), round( (2/3)*nrow(data) ))
number.prediction <- setdiff(1:nrow(data),number.train)
model.logi.train <- glm(status ~ . , data=data[number.train,], family=binomial(link="logit"))
fitted.pred       <- predict.glm(model.logi.train,
                                 newdata=data[number.prediction,], type="response")
pred.log.new      <- ifelse(fitted.pred>0.5, 1, 0)  
```


Nous utilisons ensuite la fonction table pour calculer la matrice de confusion.

```{r,eval=F}
table(pred.log.new,data[number.prediction,"status"])
```

La matrice de confusion est alors la suivante:
\begin{table}[h!]
\centering
\caption{Matrice de confusion pour la régression logistique, hors-échantillon }

\begin{tabular}{lcc}
\\[-1ex]
prédiction $\backslash$ réalisation & 0 & 1 \\
\hline
0 & 11 & 3 \\
1 & 6 & 45
\end{tabular}
\end{table}

\textbf{Attention remarque:} les "échantillons" mentionnés ci-après concernent les échantillons de voix et n'ont pas de liens avec les échantillons d'apprentissage ou de test mentionnés ci-dessus. 

Trois échantillons sur les 45 échantillons malades ne sont pas détectés par le modèle. De plus, le modèle prédit beaucoup de faux positif\footnote{individus prédits comme étant malade alors qu'ils ne le sont pas} (54\% des individus saints sont prédits comme étant malades).

\subsection{2.2. Régression par forêt aléatoire}

\subsubsection{2.2.1. Résultats de la régression par forêt aléatoire}


```{r,echo=F,message=F}
library(randomForest)
```

```{r,message=F,error=F,warning=F}
model.rforest <- randomForest(status ~ . , data=data,
                              importance=TRUE, ntree=1000, keep.forest=F)
```

Le graphique suivant montre les mesures d'importance des différentes variables. Autrement dit, chacune des variable est successivement retirée du jeu des régresseurs et une erreur quadratique moyenne est calculé à chacun des retrait. La différence entre l'erreur quadratique avec et sans un régresseur donné permet ainsi de mesurer son importance.
 
```{r}
varImpPlot(model.rforest,cex=0.6,main="Forêt aléatoire sur échantillon complet")
```

Les variables permettant la réduction de l'erreur la plus conséquente (un peu plus de 25\% pour chaque régresseur) sont les variables PPE,MDVP.Fo.Hz et spread1.


\subsubsection{2.2.2. Prédiction sur l'ensemble de l'échantillon}

La commande suivante permet de calculer le précicteur oracle du modèle sur l'échantillon complet :

```{r}
pred.rforest <- ifelse(model.rforest$predicted>0.5,1,0)  
```

Il s'agit alors de comparer cette prédiction de la régression par forêt aléatoire avec les réalisations du jeu de données.

```{r,eval=F}
table(pred.rforest,data[,"status"])
```

Le tableau ci-dessous présente la matrice de confusion

\begin{table}[h!]
\centering
\caption{Matrice de confusion pour la forêt aléatoire, en échantillon}

\begin{tabular}{lcc}
\\[-1ex]
prédiction $\backslash$ réalisation & 0 & 1 \\
\hline
0 & 36 & 4 \\
1 & 12 & 143
\end{tabular}
\end{table}

Le modèle fait strictement mieux que la régression logistique, avec un risque de premier espèce et second espèce plus faible. Ainsi, le risque de ne pas détecter un individu malade est presque deux fois plus faible dans la régression par forêt aléatoire (2.7\%) que dans la régression (4.7\%). 

\subsubsection{2.2.2. Exercice de prédiction hors-échantillon}

Tout comme dans la sous-section 2.1.2, il s'agit de tester les performances de l'algorithme hors-échantillon. Par ailleurs afin de pouvoir comparer les deux types de régressions, nous avons bien veillé à prendre le même échantillon d'apprentissage et de test. Les commandes permettant d'obtenir les prédictions sur le nouvel échantillon sont les suivantes:

```{r}
model.rforest.train <- randomForest(status ~ . , data=data[number.train,],importance=TRUE,ntree=1000)
fitted.pred          <- predict(model.rforest.train, newdata=data[number.prediction,],type="response")
pred.rforest.new     <- ifelse(fitted.pred>0.5,1,0)  
```


```{r,eval=F}
table(pred.rforest.new,data[number.prediction,"status"])
```


\begin{table}[h!]
\centering
\caption{Matrice de confusion pour la forêt aléatoire, hors-échantillon}

\begin{tabular}{lcc}
\\[-1ex]
prédiction $\backslash$ réalisation & 0 & 1 \\
\hline
0 & 11 & 1 \\
1 & 6 & 47
\end{tabular}
\end{table}

La régression par forêt aléatoire se montre également plus performante en ce qui concerne la prédiction hors-échantillon que la régression logistique. En effet, sur les 48 échantillons issus de sujets malades, la régression logistique en identifie 45 contre 47 pour la régression par forêt aléatoire. Autrement dit, le risque de ne pas identifier un indvidu malade est 3 fois plus faible pour la forêt aléatoire (2.08\%) que pour la régression logistique (6.25\%). Enfin le taux de prédictions valides pour les individus saints est identique pour les deux modèles, où 11 individus saints sur 18 sont identifiés (les autres étant identifiés comme malades à tort). Enfin, il n'y a pas de surapprentissage dans la mesure où les risques de premier et second espèce sont plus ou moins identiques à ceux obtenus sur échantillon complet.
